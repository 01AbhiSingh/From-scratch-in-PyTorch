{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":242592,"sourceType":"datasetVersion","datasetId":102285}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:32:12.679841Z","iopub.execute_input":"2025-01-26T14:32:12.680366Z","iopub.status.idle":"2025-01-26T14:32:12.693978Z","shell.execute_reply.started":"2025-01-26T14:32:12.680339Z","shell.execute_reply":"2025-01-26T14:32:12.692587Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/mnist-dataset/train-images.idx3-ubyte\n/kaggle/input/mnist-dataset/t10k-labels.idx1-ubyte\n/kaggle/input/mnist-dataset/t10k-images.idx3-ubyte\n/kaggle/input/mnist-dataset/train-labels.idx1-ubyte\n/kaggle/input/mnist-dataset/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte\n/kaggle/input/mnist-dataset/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte\n/kaggle/input/mnist-dataset/train-labels-idx1-ubyte/train-labels-idx1-ubyte\n/kaggle/input/mnist-dataset/train-images-idx3-ubyte/train-images-idx3-ubyte\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install torch torchvision numpy idx2numpy -q","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:51:38.764310Z","iopub.execute_input":"2025-01-26T14:51:38.764746Z","iopub.status.idle":"2025-01-26T14:51:45.998358Z","shell.execute_reply.started":"2025-01-26T14:51:38.764712Z","shell.execute_reply":"2025-01-26T14:51:45.997017Z"}},"outputs":[{"name":"stdout","text":"  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for idx2numpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import idx2numpy\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:09:44.683885Z","iopub.execute_input":"2025-01-26T15:09:44.684281Z","iopub.status.idle":"2025-01-26T15:09:44.689204Z","shell.execute_reply.started":"2025-01-26T15:09:44.684236Z","shell.execute_reply":"2025-01-26T15:09:44.687971Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"# Load training images and labels\ntrain_images = idx2numpy.convert_from_file('/kaggle/input/mnist-dataset/train-images-idx3-ubyte/train-images-idx3-ubyte')\ntrain_labels = idx2numpy.convert_from_file('/kaggle/input/mnist-dataset/train-labels-idx1-ubyte/train-labels-idx1-ubyte')\n\n# Load test images and labels\ntest_images = idx2numpy.convert_from_file('/kaggle/input/mnist-dataset/t10k-images-idx3-ubyte/t10k-images-idx3-ubyte')\ntest_labels = idx2numpy.convert_from_file('/kaggle/input/mnist-dataset/t10k-labels-idx1-ubyte/t10k-labels-idx1-ubyte')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:52:29.016044Z","iopub.execute_input":"2025-01-26T14:52:29.016407Z","iopub.status.idle":"2025-01-26T14:52:29.559042Z","shell.execute_reply.started":"2025-01-26T14:52:29.016379Z","shell.execute_reply":"2025-01-26T14:52:29.557975Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"print(train_images.shape)\nprint(train_labels.shape)\nprint(test_images.shape)\nprint(test_labels.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T14:53:31.271451Z","iopub.execute_input":"2025-01-26T14:53:31.272053Z","iopub.status.idle":"2025-01-26T14:53:31.278803Z","shell.execute_reply.started":"2025-01-26T14:53:31.272008Z","shell.execute_reply":"2025-01-26T14:53:31.277370Z"}},"outputs":[{"name":"stdout","text":"(60000, 28, 28)\n(60000,)\n(10000, 28, 28)\n(10000,)\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"train_images_tensor = torch.tensor(train_images, dtype=torch.float32).unsqueeze(1)\ntrain_labels_tensor = torch.tensor(train_labels, dtype = torch.int64)\n\ntest_images_tensor = torch.tensor(test_images,dtype = torch.float32).unsqueeze(1)\ntest_labels_tensor = torch.tensor(test_labels, dtype = torch.int64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:02:27.867234Z","iopub.execute_input":"2025-01-26T15:02:27.867774Z","iopub.status.idle":"2025-01-26T15:02:28.096872Z","shell.execute_reply.started":"2025-01-26T15:02:27.867739Z","shell.execute_reply":"2025-01-26T15:02:28.095849Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"#create tensordataset\ntrain_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n\ntest_dataset = TensorDataset(test_images_tensor, test_labels_tensor)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:07:26.870094Z","iopub.execute_input":"2025-01-26T15:07:26.870570Z","iopub.status.idle":"2025-01-26T15:07:26.876879Z","shell.execute_reply.started":"2025-01-26T15:07:26.870533Z","shell.execute_reply":"2025-01-26T15:07:26.875671Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"#create Dataloader\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\ntest_loader = DataLoader(test_dataset,batch_size=32,shuffle = False)\n\n#chheck a batch of data\n\nfor images,labels in train_loader:\n    print(\"batch of images shape\",images.shape)\n    print(\"batch of labels:\", labels)\n    break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:07:37.664276Z","iopub.execute_input":"2025-01-26T15:07:37.664708Z","iopub.status.idle":"2025-01-26T15:07:37.728565Z","shell.execute_reply.started":"2025-01-26T15:07:37.664674Z","shell.execute_reply":"2025-01-26T15:07:37.727419Z"}},"outputs":[{"name":"stdout","text":"batch of images shape torch.Size([32, 1, 28, 28])\nbatch of labels: tensor([1, 6, 2, 1, 0, 9, 0, 3, 2, 9, 4, 1, 2, 7, 0, 1, 3, 1, 8, 5, 2, 8, 8, 4,\n        7, 8, 3, 2, 5, 0, 8, 4])\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"train_images_tensor = train_images_tensor / 255.0\ntest_images_tensor = test_images_tensor/255.0","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:08:58.009599Z","iopub.execute_input":"2025-01-26T15:08:58.010025Z","iopub.status.idle":"2025-01-26T15:08:58.126200Z","shell.execute_reply.started":"2025-01-26T15:08:58.009998Z","shell.execute_reply":"2025-01-26T15:08:58.124962Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"\nclass CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1=nn.Conv2d(1,32,kernel_size=3,stride=1,padding=1)\n        self.pool =nn.MaxPool2d(kernel_size=2,stride=2,padding=0)\n        self.fc1=nn.Linear(32*14*14,10)\n\n    def forward(self, x):\n        x = self.pool(torch.relu(self.conv1(x)))\n        x = x.view(-1,32*14*14)\n        x = self.fc1(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:32:26.488027Z","iopub.execute_input":"2025-01-26T15:32:26.488399Z","iopub.status.idle":"2025-01-26T15:32:26.495405Z","shell.execute_reply.started":"2025-01-26T15:32:26.488370Z","shell.execute_reply":"2025-01-26T15:32:26.494099Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n# Initialize the model, loss function, and optimizer\nmodel = CNN()\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.0009)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:35:29.583205Z","iopub.execute_input":"2025-01-26T15:35:29.583766Z","iopub.status.idle":"2025-01-26T15:35:29.592343Z","shell.execute_reply.started":"2025-01-26T15:35:29.583525Z","shell.execute_reply":"2025-01-26T15:35:29.591126Z"}},"outputs":[],"execution_count":34},{"cell_type":"code","source":"for epoch in range(5):\n    for images,labels in train_loader:\n        #fw pass\n        outputs=model(images)\n        loss=criterion(outputs,labels)\n\n        #bw pass and optimization\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(f\"Epoch [{epoch+1}/5], Loss: {loss.item():.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:35:32.092553Z","iopub.execute_input":"2025-01-26T15:35:32.093010Z","iopub.status.idle":"2025-01-26T15:37:52.949687Z","shell.execute_reply.started":"2025-01-26T15:35:32.092977Z","shell.execute_reply":"2025-01-26T15:37:52.948539Z"}},"outputs":[{"name":"stdout","text":"Epoch [1/5], Loss: 0.0395\nEpoch [2/5], Loss: 0.0265\nEpoch [3/5], Loss: 0.0434\nEpoch [4/5], Loss: 0.0037\nEpoch [5/5], Loss: 0.0122\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"model.eval()  # Set the model to evaluation mode\ntest_correct = 0\ntest_total = 0\n\nwith torch.no_grad():  # Disable gradient calculation\n    for images, labels in test_loader:\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        test_total += labels.size(0)\n        test_correct += (predicted == labels).sum().item()\n\ntest_accuracy = 100 * test_correct / test_total\nprint(f\"Test Accuracy: {test_accuracy:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T15:38:32.199538Z","iopub.execute_input":"2025-01-26T15:38:32.199959Z","iopub.status.idle":"2025-01-26T15:38:33.612056Z","shell.execute_reply.started":"2025-01-26T15:38:32.199902Z","shell.execute_reply":"2025-01-26T15:38:33.610947Z"}},"outputs":[{"name":"stdout","text":"Test Accuracy: 63.53%\n","output_type":"stream"}],"execution_count":37},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}